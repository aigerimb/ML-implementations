import numpy as np
import torch
import torchvision
import matplotlib.pyplot as plt
from time import time
from torchvision import datasets, transforms
from torch import nn, optim



# Get the available device

if torch.cuda.is_available():
    dev = "cuda:0"  # Gpu
else:
    dev = "cpu"
device = torch.device(dev)



class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(784, 32),
            nn.ReLU(True))
            
        self.decoder = nn.Sequential(
            nn.Linear(32, 784),
            nn.Sigmoid())
    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        
        return x


# add Gaussian Noise
class AddGaussianNoise(object):
    def __init__(self, n_f):
        self.n_f = n_f
     
        
    def forward(self, tensor):
        return torch.clamp((tensor + torch.randn(tensor.size()) * self.n_f), 0, 1)
    
def to_img(x):
    x = x.view(x.size(0), 1, 28, 28)
    return x  


transform = transforms.Compose([transforms.ToTensor()])

trainset = datasets.MNIST('PATH_TO_STORE_TRAINSET', download=True, train=True, transform=transform)

testset = datasets.MNIST('PATH_TO_STORE_TESTSET', download=True, train=False, transform=transform)

trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)

testloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=False)


###############################################################################




n_f =0.1
num_epochs=10
model = Autoencoder()
model = model.to(device)
add_noise = AddGaussianNoise(n_f)



criterion = nn.BCELoss() # mean square error loss
optimizer = torch.optim.Adam(model.parameters(),
                                 lr=0.01, 
                                 weight_decay=1e-5)

outputs = []
for epoch in range(num_epochs):
    for data in trainloader:
        orig_img, _ = data
        orig_img = orig_img.view(-1, 784)
        noisy_img = add_noise.forward(orig_img)
        noisy_img = noisy_img.to(device)
        recon_img = model(noisy_img)
        orig_img = orig_img.to(device)
        loss = criterion(recon_img, orig_img)
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
        
        print('Epoch:{}, Loss:{:.4f}'.format(epoch+1, float(loss)))
    if epoch % 10 == 0:
        for data in testloader:
            orig_img, _ = data
            orig_img = orig_img.view(-1, 784)
            noisy_img = add_noise.forward(orig_img)
            noisy_img = noisy_img.to(device)
            recon_img = model(noisy_img)
            x_hat = to_img(recon_img.cpu().data)
            x_noisy = to_img(noisy_img.cpu().data)
            outputs.append((epoch, x_noisy, x_hat),)
            torch.save(model.state_dict(), 'autoencoder.pkl')


plt.figure(figsize=(10, 2))
for k in range(0, 10):
    
    imgs = outputs[k][2].detach().numpy()
    recon = outputs[k][1].detach().numpy()
    for i, item in enumerate(imgs):
        if i >= 9: break
        plt.subplot(2, 9, i+1)
        plt.imshow(item[0])
        
    for i, item in enumerate(recon):
        if i >= 9: break
        plt.subplot(2, 9, 9+i+1)
        plt.imshow(item[0])

plt.savefig("autoencoder0.1.png")



###############################################################################




n_f =0.5
num_epochs=10
model = Autoencoder()
model = model.to(device)
add_noise = AddGaussianNoise(n_f)



criterion = nn.BCELoss() # mean square error loss
optimizer = torch.optim.Adam(model.parameters(),
                                 lr=0.01, 
                                 weight_decay=1e-5)

outputs = []
for epoch in range(num_epochs):
    for data in trainloader:
        orig_img, _ = data
        orig_img = orig_img.view(-1, 784)
        noisy_img = add_noise.forward(orig_img)
        noisy_img = noisy_img.to(device)
        recon_img = model(noisy_img)
        orig_img = orig_img.to(device)
        loss = criterion(recon_img, orig_img)
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
        
        print('Epoch:{}, Loss:{:.4f}'.format(epoch+1, float(loss)))
    if epoch % 10 == 0:
        for data in testloader:
            orig_img, _ = data
            orig_img = orig_img.view(-1, 784)
            noisy_img = add_noise.forward(orig_img)
            noisy_img = noisy_img.to(device)
            recon_img = model(noisy_img)
            x_hat = to_img(recon_img.cpu().data)
            x_noisy = to_img(noisy_img.cpu().data)
            outputs.append((epoch, x_noisy, x_hat),)
            torch.save(model.state_dict(), 'autoencoder.pkl')


plt.figure(figsize=(10, 2))
for k in range(0, 10):
    
    imgs = outputs[k][2].detach().numpy()
    recon = outputs[k][1].detach().numpy()
    for i, item in enumerate(imgs):
        if i >= 9: break
        plt.subplot(2, 9, i+1)
        plt.imshow(item[0])
        
    for i, item in enumerate(recon):
        if i >= 9: break
        plt.subplot(2, 9, 9+i+1)
        plt.imshow(item[0])

plt.savefig("autoencoder0.5.png")





###############################################################################




n_f = 1
num_epochs=10
model = Autoencoder()
model = model.to(device)
add_noise = AddGaussianNoise(n_f)



criterion = nn.BCELoss() # mean square error loss
optimizer = torch.optim.Adam(model.parameters(),
                                 lr=0.01, 
                                 weight_decay=1e-5)

outputs = []
for epoch in range(num_epochs):
    for data in trainloader:
        orig_img, _ = data
        orig_img = orig_img.view(-1, 784)
        noisy_img = add_noise.forward(orig_img)
        noisy_img = noisy_img.to(device)
        recon_img = model(noisy_img)
        orig_img = orig_img.to(device)
        loss = criterion(recon_img, orig_img)
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
        
        print('Epoch:{}, Loss:{:.4f}'.format(epoch+1, float(loss)))
    if epoch % 10 == 0:
        for data in testloader:
            orig_img, _ = data
            orig_img = orig_img.view(-1, 784)
            noisy_img = add_noise.forward(orig_img)
            noisy_img = noisy_img.to(device)
            recon_img = model(noisy_img)
            x_hat = to_img(recon_img.cpu().data)
            x_noisy = to_img(noisy_img.cpu().data)
            outputs.append((epoch, x_noisy, x_hat),)
            torch.save(model.state_dict(), 'autoencoder.pkl')


plt.figure(figsize=(10, 2))
for k in range(0, 10):
    
    imgs = outputs[k][2].detach().numpy()
    recon = outputs[k][1].detach().numpy()
    for i, item in enumerate(imgs):
        if i >= 9: break
        plt.subplot(2, 9, i+1)
        plt.imshow(item[0])
        
    for i, item in enumerate(recon):
        if i >= 9: break
        plt.subplot(2, 9, 9+i+1)
        plt.imshow(item[0])

plt.savefig("autoencoder1.png")

# with the noise factor increased the images become extremely hard to read, but NN is still able to recognize numbers. 

